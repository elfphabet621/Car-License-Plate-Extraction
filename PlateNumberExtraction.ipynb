{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Download Car License Plate Detection Dataset from Kaggle\n",
        "Source: https://www.kaggle.com/general/74235\n",
        "\n",
        "1. Go to your account, Scroll to **API** section and **Click Expire API Token** to remove previous tokens\n",
        "\n",
        "2. Click on **Create New API Token** - It will download kaggle.json file on your machine.\n",
        "\n",
        "3. Go to your Google Colab project file and run the following commands:\n",
        "\n",
        "1) <code>! pip install -q kaggle</code>\n",
        "\n",
        "2) upload kaggle.json to your colab folder\n",
        "\n",
        "3) <code>! mkdir ~/.kaggle</code>\n",
        "\n",
        "  <code>! cp kaggle.json ~/.kaggle/</code>\n",
        "\n",
        "4) <code>! chmod 600 ~/.kaggle/kaggle.json</code>\n",
        "\n",
        "Change the permissions of the file.\n",
        "\n",
        "**Download Data**\n",
        "\n",
        "<code>! kaggle competitions download -c 'name-of-competition'</code>"
      ],
      "metadata": {
        "id": "9T0ea4zvsdja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "VjizEUGIs8Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "FUeLqpSOtgTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/car-plate-detection"
      ],
      "metadata": {
        "id": "bsgxNXzvt38M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip car-plate-detection.zip"
      ],
      "metadata": {
        "id": "_QibTMFsu5bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take a look a sample image"
      ],
      "metadata": {
        "id": "MfNpr7Vn0A6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = cv.imread('/content/images/Cars0.png')\n",
        "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "hblM2Ys9zKA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rec = cv.rectangle(img, (226,125), (419,173), (0,250,0),2)\n",
        "rec = cv.circle(rec, ((226+419)//2,(125+173)//2), 2, (255,0,0),2)\n",
        "plt.imshow(rec)"
      ],
      "metadata": {
        "id": "2i1eueZozYts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Dataset\n",
        "1. dataset.yaml\n",
        "\n",
        "```python\n",
        "#Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "\n",
        "path: ../datasets/coco128  # dataset root dir  \n",
        "train: images/train2017  # train images (relative to 'path') 128 images   \n",
        "val: images/train2017  # val images (relative to 'path') 128 images  \n",
        "test:  # test images (optional)\n",
        "#Classes\n",
        "\n",
        "names:  \n",
        "  0: person  \n",
        "  1: bicycle  \n",
        "  2: car  \n",
        "  ...\n",
        "```\n",
        "\n",
        "2. label.txt  \n",
        "one *.txt file per image (if no objects in image, no *.txt file is required). The *.txt file specifications are:\n",
        "\n",
        "- One row per object\n",
        "- Each row is <code>class x_center y_center width height</code> format.\n",
        "- Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes are in pixels, divide x_center and width by image width, and y_center and height by image height.\n",
        "- Class numbers are zero-indexed (start from 0)\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/26833433/112467037-d2568c00-8d66-11eb-8796-55402ac0d62f.png\" alt= \"label example\" width=400 height=200>\n",
        "\n",
        "3. Directories organization\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/26833433/134436012-65111ad1-9541-4853-81a6-f19a3468b75f.png\" alt= \"directories example\" width=600 height=500>"
      ],
      "metadata": {
        "id": "u3MsqYzWu-87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized_coordinates(filename, width, height, xmin, ymin, xmax, ymax):\n",
        "  xmin, xmax = xmin / width, xmax / width\n",
        "  ymin, ymax = ymin / height, ymax/ height\n",
        "\n",
        "  width = xmax-xmin\n",
        "  height = ymax-ymin\n",
        "  x_center = xmin + (width / 2)\n",
        "  y_center = ymin + (height / 2)\n",
        "\n",
        "  return x_center, y_center, width, height\n",
        "\n",
        "def write_label(filename, x_center, y_center, width, height):\n",
        "  with open(filename, mode='w') as outf:\n",
        "    outf.write(f\"{1} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "def parse_xml_tags(data):\n",
        "  tags = ['filename', 'width', 'height', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  Bs_data = BeautifulSoup(data, \"xml\")\n",
        "  d = dict()\n",
        "\n",
        "  for t in tags:\n",
        "    text = Bs_data.find(t).text\n",
        "    if all(c.isdigit() for c in text):\n",
        "      d[t] = int(text)\n",
        "    else:\n",
        "      d[t] = text\n",
        "  \n",
        "  return d\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "def build_data(dataset, mode):\n",
        "  img_dir = Path(f\"/content/plate_data/{mode}/images\")\n",
        "  img_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  label_dir = Path(f\"/content/plate_data/{mode}/labels\")\n",
        "  label_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  for file in dataset:\n",
        "    with open(f\"/content/annotations/{file}\", 'r') as f:\n",
        "      data = f.read()\n",
        "    d = parse_xml_tags(data)\n",
        "\n",
        "    shutil.copy(f\"/content/images/{d['filename']}\", f\"{img_dir}/{d['filename']}\")\n",
        "\n",
        "    x_center, y_center, width, height = normalized_coordinates(**d)\n",
        "    write_label(f\"{label_dir}/{d['filename'][:-4]}.txt\", x_center, y_center, width, height)"
      ],
      "metadata": {
        "id": "8iHZMqhaCya_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val = train_test_split(os.listdir(\"/content/annotations\"), test_size=0.1)\n",
        "\n",
        "build_data(val, 'val')\n",
        "build_data(train, 'train')"
      ],
      "metadata": {
        "id": "CQadtvcT1MH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path: /content/plate_data  # dataset root dir\n",
        "# train: /content/plate_data/train/images  # train images (relative to 'path')\n",
        "# val: /content/plate_data/val/images  # val images (relative to 'path')\n",
        "# test:  # test images (optional)\n",
        "\n",
        "# names:\n",
        "#   0: no_car_plate\n",
        "#   1: car_lisence_plate\n",
        "#   2: car"
      ],
      "metadata": {
        "id": "g2cgrEcVT-jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install requirements"
      ],
      "metadata": {
        "id": "kZW3t_NqTZVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt  # install"
      ],
      "metadata": {
        "id": "c2XjZ5nBTQrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 8 --data /content/dataset.yaml --weights yolov5s.pt --cache ram"
      ],
      "metadata": {
        "id": "lA5AvEekUVQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/yolov5/runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "id": "ZbbGCYRlVL08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "3BU_mESmV6gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/exp/weights/best.pt')"
      ],
      "metadata": {
        "id": "Tmit7ycBV7kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "zLYDlmGJj8Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!cp /content/plate_data/val/images/Cars343.png .\n",
        "im = '/content/Cars343.png'\n",
        "\n",
        "# Inference\n",
        "results = model(im)\n",
        "\n",
        "cordinates = results.xyxy[0][:, :-1]\n",
        "results.pandas().xyxy[0]"
      ],
      "metadata": {
        "id": "jHiipvcwiNp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grab car plate number"
      ],
      "metadata": {
        "id": "nSw7O88Ubjd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "u5qYKQDBmXj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_plate_number(results, frame, reader):\n",
        "  n = len(results)\n",
        "  x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
        "\n",
        "  for i in range(n):\n",
        "    row = cordinates[i] # Iterate through each image\n",
        "    if row[4] >= 0.2: ## Take img with 0.5 confidence\n",
        "      xmin, ymin, xmax, ymax = row[:4]\n",
        "      plate = frame[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
        "\n",
        "      ## Preprocess Plate\n",
        "      gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n",
        "      blurred = cv.bilateralFilter(gray, 17, 15, 15)\n",
        "      ret, thresh = cv.threshold(blurred, 125, 255, cv.THRESH_BINARY)\n",
        "\n",
        "      ## OCR\n",
        "      text = reader.readtext(thresh)[0][-2]\n",
        "\n",
        "      plot_img = frame.copy()\n",
        "\n",
        "      cv.rectangle(plot_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2) ## BBox\n",
        "      cv.rectangle(plot_img, (int(xmin), int(ymin-20)), (int(xmax), int(ymin)), (0, 255,0), -1) ## for text label background\n",
        "      final_img = cv.putText(plot_img, f\"{text}\", (int(xmin), int(ymin)), cv.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255), 2)\n",
        "\n",
        "      cv.imwrite(f'labeled_img_{i}.jpg', cv.cvtColor(final_img, cv.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "mAClwHQhkIgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import easyocr\n",
        "\n",
        "reader = easyocr.Reader(['en'])\n",
        "cordinates = cordinates.cpu().numpy()"
      ],
      "metadata": {
        "id": "gJNwaZFWXjCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame = cv.imread(im) ### reading the image\n",
        "frame = cv.cvtColor(frame,cv.COLOR_BGR2RGB)\n",
        "        \n",
        "read_plate_number(cordinates, frame, reader)"
      ],
      "metadata": {
        "id": "uRXKlhSdpI74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}